{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc83c0a9",
        "outputId": "a6d0642a-4a72-42da-ddb7-9b5f650f45e3"
      },
      "source": [
        "!pip install faiss-cpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.1 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.12.0-cp312-cp312-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m67.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d12jEkzRqiSU",
        "outputId": "e5291559-e922-45ea-89c6-fb1adea366a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
            "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m225.3/232.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3183b314",
        "outputId": "87f22892-a07f-4daf-94d9-e91b8ede9459"
      },
      "source": [
        "!pip install PyPDF2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyPDF2 in /usr/local/lib/python3.12/dist-packages (3.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35710d75",
        "outputId": "fd1f9581-296f-4109-8f72-870b80ca992b"
      },
      "source": [
        "!pip install docx2txt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.9-py3-none-any.whl.metadata (529 bytes)\n",
            "Downloading docx2txt-0.9-py3-none-any.whl (4.0 kB)\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyAgB6VC1zkti8Ri8-sFnZWFcgmlEO7Ah-I\""
      ],
      "metadata": {
        "id": "gcqo8wmvrYZu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import faiss\n",
        "from PyPDF2 import PdfReader\n",
        "import docx2txt\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import google.generativeai as genai\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "def load_text_from_file(file_path):\n",
        "    text = \"\"\n",
        "    if file_path.endswith(\".pdf\"):\n",
        "        reader = PdfReader(file_path)\n",
        "        for page in reader.pages:\n",
        "            text += page.extract_text() + \"\\n\"\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported file type: {file_path}\")\n",
        "    return text\n",
        "\n",
        "def split_text(text, chunk_size=1000, overlap=200):\n",
        "    chunks = []\n",
        "    start = 0\n",
        "    while start < len(text):\n",
        "        end = min(start + chunk_size, len(text))\n",
        "        chunks.append(text[start:end])\n",
        "        start += chunk_size - overlap\n",
        "    return chunks\n",
        "\n",
        "\n",
        "def build_faiss_index(chunks, model_name=\"sentence-transformers/all-MiniLM-L6-v2\"):\n",
        "    embedding_model = SentenceTransformer(model_name)\n",
        "    embeddings = embedding_model.encode(chunks, convert_to_numpy=True, normalize_embeddings=True)\n",
        "\n",
        "    index = faiss.IndexFlatIP(embeddings.shape[1])\n",
        "    index.add(embeddings)\n",
        "    return index, embedding_model\n",
        "\n",
        "\n",
        "def rag_query(question, index, documents, embedding_model, top_k=3):\n",
        "\n",
        "    q_embedding = embedding_model.encode([question], convert_to_numpy=True, normalize_embeddings=True)\n",
        "    D, I = index.search(q_embedding, k=top_k)\n",
        "    retrieved_chunks = [documents[i] for i in I[0]]\n",
        "    context = \"\\n\".join(retrieved_chunks)\n",
        "    prompt = f\"Context:\\n{context}\\n\\nQuestion: {question}\\nAnswer:\"\n",
        "    model = genai.GenerativeModel(\"gemini-1.5-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "\n",
        "    return response.text\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    files = [\n",
        "        \"/content/2307.06435v10.pdf\",\n",
        "        \"/content/NIPS-2017-attention-is-all-you-need-Paper.pdf\"\n",
        "    ]\n",
        "\n",
        "\n",
        "    all_chunks = []\n",
        "    for f in files:\n",
        "        try:\n",
        "            text = load_text_from_file(f)\n",
        "            chunks = split_text(text)\n",
        "            all_chunks.extend(chunks)\n",
        "        except FileNotFoundError:\n",
        "            print(f\"Error: File not found at {f}. Skipping.\")\n",
        "        except ValueError as e:\n",
        "            print(f\"Error processing file {f}: {e}. Skipping.\")\n",
        "\n",
        "\n",
        "\n",
        "    if all_chunks:\n",
        "      index, embedding_model = build_faiss_index(all_chunks)\n",
        "      print(\"Documents processed and FAISS index built!\")\n",
        "\n",
        "\n",
        "      while True:\n",
        "          question = input(\"\\nAsk a question about your documents (or type 'exit' to quit): \")\n",
        "          if question.lower() == \"exit\":\n",
        "              break\n",
        "          try:\n",
        "              answer = rag_query(question, index, all_chunks, embedding_model)\n",
        "              print(\"\\n--- Answer ---\")\n",
        "              print(answer)\n",
        "          except Exception as e:\n",
        "              print(f\"Error: {e}\")\n",
        "    else:\n",
        "      print(\"No documents were successfully processed. Cannot build FAISS index.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ItOcnapLrle5",
        "outputId": "3742cb04-b1f1-40ce-977a-f0533b8aae5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents processed and FAISS index built!\n",
            "\n",
            "Ask a question about your documents (or type 'exit' to quit): write about attention is all you need\n",
            "\n",
            "--- Answer ---\n",
            "\"Attention is All You Need\" is a landmark paper that introduced the Transformer architecture, a novel neural network architecture based solely on attention mechanisms, dispensing with recurrence and convolutions entirely.  This was a significant departure from previous sequence-to-sequence models which relied heavily on recurrent neural networks (RNNs) like LSTMs and GRUs.  The key innovation was the use of **self-attention**, allowing the model to weigh the importance of different parts of the input sequence when processing each element.\n",
            "\n",
            "The paper demonstrated that self-attention could achieve state-of-the-art results on machine translation tasks, surpassing previous RNN-based models in both speed and quality.  This was due to several factors:\n",
            "\n",
            "* **Parallelization:** Unlike RNNs, which process sequences sequentially, self-attention can be computed in parallel, significantly speeding up training and inference.  This parallel processing is a major advantage for handling long sequences.\n",
            "\n",
            "* **Long-range dependencies:** RNNs struggle with capturing long-range dependencies in sequences because of the vanishing gradient problem. Self-attention, on the other hand, can directly attend to any part of the input sequence, regardless of distance, allowing it to capture these dependencies more effectively.\n",
            "\n",
            "* **Interpretability:** The attention weights provide insights into how the model processes information, making it more interpretable than black-box models like RNNs.  By examining the attention weights, one can understand which parts of the input sequence the model is focusing on when generating each output element.\n",
            "\n",
            "The Transformer architecture, as introduced in \"Attention is All You Need,\" consists of an encoder and a decoder.  Both the encoder and decoder are composed of stacked layers, each containing a multi-head self-attention mechanism and a feed-forward neural network.  The multi-head attention allows the model to attend to different aspects of the input sequence simultaneously.  Positional encoding is also added to the input embeddings to provide information about the order of words, since self-attention is inherently permutation-invariant.\n",
            "\n",
            "The impact of \"Attention is All You Need\" has been immense.  The Transformer architecture has become the foundation for numerous successful models in natural language processing (NLP), including BERT, GPT, and many others.  Its influence extends beyond NLP, finding applications in computer vision and other areas.  The paper's introduction of self-attention has fundamentally changed the landscape of deep learning, leading to faster, more powerful, and more interpretable models for various sequence processing tasks.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}